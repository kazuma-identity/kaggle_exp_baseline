{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import plotly.colors as pc\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import japanize_matplotlib\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import rich\n",
    "from rich import pretty, print\n",
    "from rich.console import Console\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold, TimeSeriesSplit\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import rankdata\n",
    "from scipy.optimize import minimize\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Configurations (TODO: プロジェクトごとに変更)\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 1\n",
    "    COMPETITION = ''  # TODO: コンペ名\n",
    "    DATA_PATH = Path('../input')\n",
    "    OOF_DATA_PATH = Path(f'../oof/{VER}')\n",
    "    MODEL_DATA_PATH = Path(f'../models/{VER}')\n",
    "    SUB_DATA_PATH = Path(f'../submission/{VER}')\n",
    "    METHOD_LIST = ['lightgbm', 'xgboost']  # 使用するモデル\n",
    "    SEED = 57\n",
    "    SEED_LIST = [1, 57, 143, 2026, 9999]\n",
    "    n_folds = 5\n",
    "    target_col = ''  # TODO: ターゲットカラム名\n",
    "    id_col = ''  # TODO: IDカラム名\n",
    "    metric = ''  # TODO: 評価指標\n",
    "    num_boost_round = 100000\n",
    "    early_stopping_round = 100\n",
    "    verbose = 250\n",
    "\n",
    "    feature_drop_cols = []  # TODO: 特徴量から除外するカラム\n",
    "\n",
    "    categorical_cols = []  # TODO: カテゴリカル変数\n",
    "\n",
    "    # LightGBM (二値分類)\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves': 63,\n",
    "        'colsample_bytree': 0.4,\n",
    "        'reg_alpha': 0.4,\n",
    "        'seed': SEED,\n",
    "    }\n",
    "\n",
    "    # XGBoost (二値分類)\n",
    "    classification_xgb_params = {\n",
    "        'device': 'cuda',\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'learning_rate': 0.01,\n",
    "        'max_depth': 8,\n",
    "        'enable_categorical': True,\n",
    "        'random_state': SEED,\n",
    "    }\n",
    "\n",
    "    # CatBoost (二値分類)\n",
    "    classification_cat_params = {\n",
    "        'eval_metric': 'AUC',\n",
    "        'learning_rate': 0.01,\n",
    "        'iterations': num_boost_round,\n",
    "        'depth': 8,\n",
    "        'random_seed': SEED,\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "\n",
    "    model_weight_dict = {'lightgbm': 0.50, 'xgboost': 0.50}  # 初期重み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Setup\n",
    "# ====================================================\n",
    "os.makedirs(CFG.MODEL_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(CFG.OOF_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(CFG.SUB_DATA_PATH, exist_ok=True)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "# Load Data (TODO: プロジェクトごとに実装)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: データ読み込みを実装\n",
    "# train_df = pd.read_csv(CFG.DATA_PATH / 'train.csv')\n",
    "# test_df = pd.read_csv(CFG.DATA_PATH / 'test.csv')\n",
    "# sample_submission_df = pd.read_csv(CFG.DATA_PATH / 'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess-header",
   "metadata": {},
   "source": [
    "# Preprocess (TODO: プロジェクトごとに実装)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 前処理を実装\n",
    "# def Preprocessing(train_df, test_df):\n",
    "#     feature_cols = [col for col in train_df.columns if col not in [CFG.target_col, CFG.id_col] + CFG.feature_drop_cols]\n",
    "#     return train_df, test_df, feature_cols\n",
    "#\n",
    "# train_df, test_df, FEATURES = Preprocessing(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modeling-header",
   "metadata": {},
   "source": [
    "# Modeling (汎用関数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Training Functions\n",
    "# ====================================================\n",
    "def lightgbm_training(x_train, y_train, x_valid, y_valid, params=None):\n",
    "    if params is None:\n",
    "        params = CFG.classification_lgb_params\n",
    "    lgb_train = lgb.Dataset(x_train, y_train)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params=params,\n",
    "        train_set=lgb_train,\n",
    "        num_boost_round=CFG.num_boost_round,\n",
    "        valid_sets=[lgb_train, lgb_valid],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=CFG.early_stopping_round, verbose=CFG.verbose),\n",
    "            lgb.log_evaluation(CFG.verbose),\n",
    "        ]\n",
    "    )\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def xgboost_training(x_train, y_train, x_valid, y_valid, params=None):\n",
    "    if params is None:\n",
    "        params = CFG.classification_xgb_params\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain=xgb_train,\n",
    "        num_boost_round=CFG.num_boost_round,\n",
    "        evals=[(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose_eval=CFG.verbose\n",
    "    )\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def catboost_training(x_train, y_train, x_valid, y_valid, params=None):\n",
    "    if params is None:\n",
    "        params = CFG.classification_cat_params\n",
    "    cat_train = Pool(data=x_train, label=y_train)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid)\n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(\n",
    "        cat_train,\n",
    "        eval_set=[cat_valid],\n",
    "        early_stopping_rounds=CFG.early_stopping_round,\n",
    "        verbose=CFG.verbose,\n",
    "        use_best_model=True\n",
    "    )\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Cross Validation Training\n",
    "# ====================================================\n",
    "def apply_fold_rank_transform(oof_df, pred_col):\n",
    "    \"\"\"各foldの予測値をfold内でrank変換\"\"\"\n",
    "    rank_predictions = np.zeros(len(oof_df))\n",
    "    for fold in oof_df['fold'].unique():\n",
    "        mask = oof_df['fold'] == fold\n",
    "        fold_pred = oof_df.loc[mask, pred_col].values\n",
    "        rank_predictions[mask] = rankdata(fold_pred) / len(fold_pred)\n",
    "    return rank_predictions\n",
    "\n",
    "\n",
    "def gradient_boosting_model_cv_training(method, train_df, features, target_col=None, id_col=None):\n",
    "    \"\"\"勾配ブースティングモデルのCV学習\"\"\"\n",
    "    if target_col is None:\n",
    "        target_col = CFG.target_col\n",
    "    if id_col is None:\n",
    "        id_col = CFG.id_col\n",
    "\n",
    "    seed_oof_predictions = np.zeros(len(train_df))\n",
    "\n",
    "    for seed in CFG.SEED_LIST:\n",
    "        print(f'Using seed {seed}')\n",
    "\n",
    "        oof_predictions = np.zeros(len(train_df))\n",
    "        oof_fold = np.zeros(len(train_df))\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=seed)\n",
    "        for fold, (train_index, valid_index) in enumerate(skf.split(X=train_df, y=train_df[target_col])):\n",
    "            print('-' * 50)\n",
    "            print(f'{method} training fold {fold + 1} in seed {seed}')\n",
    "\n",
    "            x_train = train_df[features].iloc[train_index]\n",
    "            y_train = train_df[target_col].iloc[train_index]\n",
    "            x_valid = train_df[features].iloc[valid_index]\n",
    "            y_valid = train_df[target_col].iloc[valid_index]\n",
    "\n",
    "            if method == 'lightgbm':\n",
    "                model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == 'xgboost':\n",
    "                model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid)\n",
    "            elif method == 'catboost':\n",
    "                model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid)\n",
    "            else:\n",
    "                raise ValueError(f'Unknown method: {method}')\n",
    "\n",
    "            # Save model\n",
    "            pickle.dump(model, open(CFG.MODEL_DATA_PATH / f'{method}_fold{fold + 1}_seed{seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "            oof_predictions[valid_index] = valid_pred\n",
    "            oof_fold[valid_index] = fold + 1\n",
    "\n",
    "            del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "            gc.collect()\n",
    "\n",
    "        # OOF保存\n",
    "        oof_df = pd.DataFrame({\n",
    "            id_col: train_df[id_col],\n",
    "            target_col: train_df[target_col],\n",
    "            f'{method}_prediction': oof_predictions,\n",
    "            'fold': oof_fold\n",
    "        })\n",
    "        oof_df.to_csv(CFG.OOF_DATA_PATH / f'oof_{method}_seed{seed}_ver{CFG.VER}.csv', index=False)\n",
    "\n",
    "        # スコア計算\n",
    "        rank_predictions = apply_fold_rank_transform(oof_df, f'{method}_prediction')\n",
    "        score = roc_auc_score(train_df[target_col], rank_predictions)\n",
    "        print(f'{method} seed {seed} OOF CV auc (rank transformed): {score:.6f}')\n",
    "\n",
    "        seed_oof_predictions += oof_predictions\n",
    "\n",
    "    # seed平均\n",
    "    seed_oof_predictions /= len(CFG.SEED_LIST)\n",
    "    oof_avg_df = pd.DataFrame({\n",
    "        id_col: train_df[id_col],\n",
    "        target_col: train_df[target_col],\n",
    "        f'{method}_prediction': seed_oof_predictions\n",
    "    })\n",
    "    oof_avg_df.to_csv(CFG.OOF_DATA_PATH / f'oof_{method}_seed_avg_ver{CFG.VER}.csv', index=False)\n",
    "\n",
    "    score_raw = roc_auc_score(train_df[target_col], seed_oof_predictions)\n",
    "    print(f'{method} seed averaged OOF CV auc (raw): {score_raw:.6f}')\n",
    "\n",
    "\n",
    "def Learning(train_df, features):\n",
    "    \"\"\"全モデルの学習を実行\"\"\"\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        gradient_boosting_model_cv_training(method, train_df, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weight-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Weight Optimization\n",
    "# ====================================================\n",
    "def get_rank_transformed_oof(method):\n",
    "    \"\"\"各seedのOOFを読み込み、fold内rank変換を適用して平均\"\"\"\n",
    "    all_rank_preds = []\n",
    "    for seed in CFG.SEED_LIST:\n",
    "        oof_df = pd.read_csv(CFG.OOF_DATA_PATH / f'oof_{method}_seed{seed}_ver{CFG.VER}.csv')\n",
    "        rank_pred = apply_fold_rank_transform(oof_df, f'{method}_prediction')\n",
    "        all_rank_preds.append(rank_pred)\n",
    "    return np.mean(all_rank_preds, axis=0)\n",
    "\n",
    "\n",
    "def optimize_weights(train_df, target_col=None):\n",
    "    \"\"\"OOF予測を使って各モデルの重みを最適化する\"\"\"\n",
    "    if target_col is None:\n",
    "        target_col = CFG.target_col\n",
    "\n",
    "    oof_preds = {}\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        oof_preds[method] = get_rank_transformed_oof(method)\n",
    "\n",
    "    y_true = train_df[target_col].values\n",
    "\n",
    "    def objective(weights):\n",
    "        final_pred = np.zeros(len(y_true))\n",
    "        for i, method in enumerate(CFG.METHOD_LIST):\n",
    "            final_pred += weights[i] * oof_preds[method]\n",
    "        return -roc_auc_score(y_true, final_pred)\n",
    "\n",
    "    initial_weights = [1.0 / len(CFG.METHOD_LIST)] * len(CFG.METHOD_LIST)\n",
    "    constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "    bounds = [(0, 1)] * len(CFG.METHOD_LIST)\n",
    "\n",
    "    result = minimize(\n",
    "        objective,\n",
    "        initial_weights,\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        constraints=constraints\n",
    "    )\n",
    "\n",
    "    optimal_weights = result.x\n",
    "    optimal_score = -result.fun\n",
    "\n",
    "    print('=' * 50)\n",
    "    print('Weight Optimization Results:')\n",
    "    print('=' * 50)\n",
    "    for method, weight in zip(CFG.METHOD_LIST, optimal_weights):\n",
    "        print(f'{method}: {weight:.4f}')\n",
    "    print(f'Optimized OOF AUC: {optimal_score:.6f}')\n",
    "    print('=' * 50)\n",
    "\n",
    "    return {method: weight for method, weight in zip(CFG.METHOD_LIST, optimal_weights)}, optimal_score\n",
    "\n",
    "\n",
    "def scoring_cv(train_df, weights=None, target_col=None):\n",
    "    \"\"\"OOFスコアを計算する\"\"\"\n",
    "    if weights is None:\n",
    "        weights = CFG.model_weight_dict\n",
    "    if target_col is None:\n",
    "        target_col = CFG.target_col\n",
    "\n",
    "    preds = np.zeros(len(train_df))\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        rank_pred = get_rank_transformed_oof(method)\n",
    "        preds += rank_pred * weights[method]\n",
    "\n",
    "    score = roc_auc_score(train_df[target_col], preds)\n",
    "    print(f'OOF CV auc (rank transformed): {score:.6f}')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 学習実行\n",
    "# Learning(train_df, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 重み最適化\n",
    "# optimized_weights, optimized_score = optimize_weights(train_df)\n",
    "# scoring_cv(train_df, CFG.model_weight_dict)\n",
    "# scoring_cv(train_df, optimized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Feature Importance\n",
    "# ====================================================\n",
    "def plot_feature_importance(features, seed=None, fold=1, figsize=(10, 20)):\n",
    "    \"\"\"LightGBMの特徴量重要度を可視化\"\"\"\n",
    "    if seed is None:\n",
    "        seed = CFG.SEED\n",
    "    model = pickle.load(open(CFG.MODEL_DATA_PATH / f'lightgbm_fold{fold}_seed{seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "    importance_df = pd.DataFrame(\n",
    "        model.feature_importance(importance_type='gain'),\n",
    "        index=features,\n",
    "        columns=['importance']\n",
    "    )\n",
    "    importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.barplot(data=importance_df, x='importance', y=importance_df.index)\n",
    "    plt.title('Feature Importance (Gain)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return importance_df\n",
    "\n",
    "# TODO: 可視化実行\n",
    "# importance_df = plot_feature_importance(FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-header",
   "metadata": {},
   "source": [
    "# Inference (汎用関数)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Inference Functions\n",
    "# ====================================================\n",
    "def lightgbm_inference(x_test):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for seed in CFG.SEED_LIST:\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(CFG.MODEL_DATA_PATH / f'lightgbm_fold{fold + 1}_seed{seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            pred = model.predict(x_test)\n",
    "            rank_pred = rankdata(pred) / len(pred)\n",
    "            test_pred += rank_pred\n",
    "    return test_pred / (CFG.n_folds * len(CFG.SEED_LIST))\n",
    "\n",
    "\n",
    "def xgboost_inference(x_test):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for seed in CFG.SEED_LIST:\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(CFG.MODEL_DATA_PATH / f'xgboost_fold{fold + 1}_seed{seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            pred = model.predict(xgb.DMatrix(x_test), enable_categorical=True)\n",
    "            rank_pred = rankdata(pred) / len(pred)\n",
    "            test_pred += rank_pred\n",
    "    return test_pred / (CFG.n_folds * len(CFG.SEED_LIST))\n",
    "\n",
    "\n",
    "def catboost_inference(x_test):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for seed in CFG.SEED_LIST:\n",
    "        for fold in range(CFG.n_folds):\n",
    "            model = pickle.load(open(CFG.MODEL_DATA_PATH / f'catboost_fold{fold + 1}_seed{seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "            pred = model.predict_proba(x_test)[:, 1]\n",
    "            rank_pred = rankdata(pred) / len(pred)\n",
    "            test_pred += rank_pred\n",
    "    return test_pred / (CFG.n_folds * len(CFG.SEED_LIST))\n",
    "\n",
    "\n",
    "def gradient_boosting_model_inference(method, test_df, features):\n",
    "    x_test = test_df[features]\n",
    "    if method == 'lightgbm':\n",
    "        return lightgbm_inference(x_test)\n",
    "    elif method == 'xgboost':\n",
    "        return xgboost_inference(x_test)\n",
    "    elif method == 'catboost':\n",
    "        return catboost_inference(x_test)\n",
    "    else:\n",
    "        raise ValueError(f'Unknown method: {method}')\n",
    "\n",
    "\n",
    "def Predicting(test_df, features, weights=None):\n",
    "    \"\"\"テストデータに対して予測を行う\"\"\"\n",
    "    if weights is None:\n",
    "        weights = CFG.model_weight_dict\n",
    "\n",
    "    output_df = test_df.copy()\n",
    "    output_df['pred'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        output_df[f'{method}_pred'] = gradient_boosting_model_inference(method, test_df, features)\n",
    "        output_df['pred'] += weights[method] * output_df[f'{method}_pred']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-inference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 推論実行\n",
    "# test_pred = Predicting(test_df, FEATURES, optimized_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submission-header",
   "metadata": {},
   "source": [
    "# Submission (TODO: プロジェクトごとに実装)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: サブミッション作成\n",
    "# submission_df = sample_submission_df.copy()\n",
    "# submission_df = submission_df.merge(\n",
    "#     test_pred[[CFG.id_col, 'pred']],\n",
    "#     on=CFG.id_col,\n",
    "#     how='left'\n",
    "# )\n",
    "# submission_df = submission_df[[CFG.id_col, 'pred']]\n",
    "# submission_df.to_csv(CFG.SUB_DATA_PATH / f'submission_ver{CFG.VER}.csv', index=False)\n",
    "# print(f'Submission saved to {CFG.SUB_DATA_PATH / f\"submission_ver{CFG.VER}.csv\"}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
